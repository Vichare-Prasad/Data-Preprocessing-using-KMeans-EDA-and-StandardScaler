# Data-Preprocessing-using-KMeans-EDA-and-StandardScaler

**PROBLEM STATEMENT**
A retail company that operates across multiple regions is seeking to gain deeper insights into its customers in order to improve sales and enhance customer retention. The company sells a wide range of products and collects daily transaction data from its operations. However, this data has not yet been fully leveraged to drive business decisions.

Management has identified three key objectives:
**1. Analyze customer behavior**
Understand purchasing patterns, frequency, and preferences.
Identify high-value customers and at-risk customers.

**2.Segment customers**
Group customers based on purchasing behavior, spending capacity, and engagement.
Enable targeted marketing campaigns tailored to different customer segments.

**3.Provide data-driven recommendations**

Suggest strategies to optimize marketing campaigns.
Recommend personalized offers and loyalty programs to boost sales.
Provide actionable insights for improving customer retention and lifetime value.

**Project Setup (Optional for Jupyter , recommend GoogleColab)**

**Step 1:** Get the Project Files
Download or clone this repository onto your system.
**(If you‚Äôre using Git: git clone <repo_link>)**

**Step 2:** Install Python
Make sure Python (preferably 3.8+) is installed.
You can check by running:
---
python --version
---

**Step 3:** Set Up a Virtual Environment (Optional but recommended üõ°Ô∏è)
This keeps your project dependencies clean and separate.
---
python -m venv venv
---

**Step 4:** Install Required Libraries
We need a few powerful Python libraries that make this project work:
---
pip install pandas numpy matplotlib seaborn scikit-learn
---

**pandas ‚Üí For handling and cleaning retail data.
numpy ‚Üí For fast math and array operations.
matplotlib & seaborn ‚Üí For beautiful graphs and visualizations.
scikit-learn ‚Üí For machine learning (KMeans clustering + scaling).**

**Step 5:** Open the Project
If you‚Äôre using Jupyter Notebook:
jupyter notebook Untitled5.ipynb
If you‚Äôre using VS Code or PyCharm, just open the .ipynb file and run the cells one by one.

**Step 6:** Run the Notebook
Start by loading the dataset (already included in the code).
Follow the notebook cells step by step:

1.Import libraries 
2.Load the dataset 
3.Clean duplicates and missing values 
4.Explore data with graphs 
5.Apply StandardScaler 
6.Run KMeans clustering 
7.Visualize clusters 


![alt text](https://github.com/Vichare-Prasad/Data-Preprocessing-using-KMeans-EDA-and-StandardScaler/blob/main/Data%20Cleaning.png "Data Cleaning")

![alt text](https://github.com/Vichare-Prasad/Data-Preprocessing-using-KMeans-EDA-and-StandardScaler/blob/main/RFM%20Data.png " RFM DATA")

![alt text](https://github.com/Vichare-Prasad/Data-Preprocessing-using-KMeans-EDA-and-StandardScaler/blob/main/plot%20graph%20using%20Elbow%20Method.png "Graph Using Elbow Method")

![alt text](https://github.com/Vichare-Prasad/Data-Preprocessing-using-KMeans-EDA-and-StandardScaler/blob/main/Output.png "Output")






